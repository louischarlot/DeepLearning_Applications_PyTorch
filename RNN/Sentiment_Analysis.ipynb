{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5nvhJqpkqeQZ"
      },
      "source": [
        "# Sentiment Analysis of Yelp reviews: Word Embeddings and LSTM\n",
        "\n",
        "In this notebook, we implement a sentiment analysis to associate stars (from 1 to 5) to the reviews of the [YelpReviewFull dataset](https://pytorch.org/text/stable/datasets.html#yelpreviewfull). \n",
        "This dataset consists of reviews from Yelp, and is extracted from the Yelp Dataset Challenge 2015 data. \n",
        "A data point of this dataset comprises a review's text and the corresponding label (1 to 5 stars).\n",
        "\n",
        "For this, we will first use ..WORD EMBEDDINGS... TO...    [ResNet](https://arxiv.org/abs/1512.03385)\n",
        "\n",
        "Then, we will use XXX... to...    [ResNet](https://arxiv.org/abs/1512.03385)\n",
        "\n",
        "We achieve a XX% ...\n",
        "\n",
        "To build this notebook, the hints given by the [Udacity](https://github.com/udacity/deep-learning-v2-pytorch/blob/master/sentiment-rnn/Sentiment_RNN_Solution.ipynb) team have been very useful.\n",
        "\n",
        "\n",
        "\n",
        "We decide to group **4 and 5 stars** reviews as **\"good\"**, **3 stars** as **\"neutral\"**, and **1 and 2 stars** as **\"bad\"**.\n",
        "\n",
        "In the following, we will try to **predict** if a review is good, neutral or bad.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To begin with, we install the libraries that are necessary to run the code on [Google Colab](https://colab.research.google.com/)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UsageError: unrecognized arguments: To hide the output of the cell.\n"
          ]
        }
      ],
      "source": [
        "%%capture  # To hide the output of the cell.\n",
        "%%bash\n",
        "pip install torch==1.11.0\n",
        "pip install folium==0.2.1\n",
        "pip install torchdata\n",
        "pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "9uM_lvsCqeQb"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torchdata\n",
        "from torch import nn, optim\n",
        "import torch.nn.functional as F\n",
        "from torchtext import transforms, utils, models#, datasets "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data pre-processing:\n",
        "\n",
        "### Data loading and reduction:\n",
        "\n",
        "We download the data with the [Hugging Face](https://huggingface.co/) library **datasets**. \n",
        "\n",
        "(The direct downloading from torchtext.datsets is impossible for now, because of a bug that will be corrected in the next version of PyTorch.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Reusing dataset yelp_review_full (/Users/louis/.cache/huggingface/datasets/yelp_review_full/yelp_review_full/1.0.0/e8e18e19d7be9e75642fc66b198abadb116f73599ec89a69ba5dd8d1e57ba0bf)\n",
            "Reusing dataset yelp_review_full (/Users/louis/.cache/huggingface/datasets/yelp_review_full/yelp_review_full/1.0.0/e8e18e19d7be9e75642fc66b198abadb116f73599ec89a69ba5dd8d1e57ba0bf)\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "train_data = load_dataset(\"yelp_review_full\", split=\"train\")\n",
        "test_data = load_dataset(\"yelp_review_full\", split=\"test\")\n",
        "\n",
        "reviews = train_data['text'] + test_data['text']\n",
        "stars = train_data['label'] + test_data['label']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We observe some data to see of all is OK."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "A review example:   \"Been going to Dr. Goldberg for over 10 years. I think I was one of his 1st patients when he started at MHMG. He's been great over the years and is really all about the big picture. It is because of him, not my now former gyn Dr. Markoff, that I found out I have fibroids. He explores all options with you and is very patient and understanding. He doesn't judge and asks all the right questions. Very thorough and wants to be kept in the loop on every aspect of your medical health and your life.\"\n",
            "\n",
            "The related label (number of stars):  3 stars\n"
          ]
        }
      ],
      "source": [
        "print(f\"A review example:   \\\"{reviews[2]}\\\"\")\n",
        "print()\n",
        "print(f\"The related label (number of stars):  {stars[2]} stars\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The full dataset contains a very big number of reviews: 700,000."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of reviews of the full dataset:  700000\n"
          ]
        }
      ],
      "source": [
        "print(f\"Number of reviews of the full dataset:  {len(reviews)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let us look at the full distribution of stars given to the reviews."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of reviews with 1 STAR of the INITIAL dataset:  20.0 %\n",
            "Number of reviews with 2 STARS of the INITIAL dataset:  20.0 %\n",
            "Number of reviews with 3 STARS of the INITIAL dataset:  20.0 %\n",
            "Number of reviews with 4 STARS of the INITIAL dataset:  20.0 %\n",
            "Number of reviews with 5 STARS of the INITIAL dataset:  20.0 %\n"
          ]
        }
      ],
      "source": [
        "from collections import Counter\n",
        "\n",
        "print(f\"Number of reviews with 1 STAR of the INITIAL dataset:  {100*stars.count(0)/len(stars)} %\")\n",
        "print(f\"Number of reviews with 2 STARS of the INITIAL dataset:  {100*stars.count(1)/len(stars)} %\")\n",
        "print(f\"Number of reviews with 3 STARS of the INITIAL dataset:  {100*stars.count(2)/len(stars)} %\")\n",
        "print(f\"Number of reviews with 4 STARS of the INITIAL dataset:  {100*stars.count(3)/len(stars)} %\")\n",
        "print(f\"Number of reviews with 5 STARS of the INITIAL dataset:  {100*stars.count(4)/len(stars)} %\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We decide to keep only **20%** of the original YelpReviewsFull dataset for our analysis (140,000 reviews!).\n",
        "We carry out the selection **by preserving the equal distribution of stars**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of reviews kept for our analysis:  140000\n"
          ]
        }
      ],
      "source": [
        "# We choose the indices that will be used\n",
        "indices_1_Star = [index for index in range(len(reviews)) if stars[index]==0]\n",
        "indices_2_Star = [index for index in range(len(reviews)) if stars[index]==1]\n",
        "indices_3_Star = [index for index in range(len(reviews)) if stars[index]==2]\n",
        "indices_4_Star = [index for index in range(len(reviews)) if stars[index]==3]\n",
        "indices_5_Star = [index for index in range(len(reviews)) if stars[index]==4]\n",
        "\n",
        "# We shuffle these indexes and delect randomly 20% of them\n",
        "np.random.seed(123)\n",
        "np.random.shuffle(indices_1_Star)\n",
        "np.random.shuffle(indices_2_Star)\n",
        "np.random.shuffle(indices_3_Star)\n",
        "np.random.shuffle(indices_4_Star)\n",
        "np.random.shuffle(indices_5_Star)\n",
        "selected_indices_1_Star = indices_1_Star[:len(indices_1_Star)//5]\n",
        "selected_indices_2_Star = indices_2_Star[:len(indices_2_Star)//5]\n",
        "selected_indices_3_Star = indices_3_Star[:len(indices_3_Star)//5]\n",
        "selected_indices_4_Star = indices_4_Star[:len(indices_4_Star)//5]\n",
        "selected_indices_5_Star = indices_5_Star[:len(indices_5_Star)//5]\n",
        "\n",
        "selected_indices = selected_indices_1_Star + selected_indices_2_Star + selected_indices_3_Star + selected_indices_4_Star + selected_indices_5_Star\n",
        "reviews = [reviews[index] for index in selected_indices]\n",
        "stars = [stars[index] for index in selected_indices]\n",
        "\n",
        "print(f\"Number of reviews kept for our analysis:  {len(reviews)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We check that the distribution of different stars is still the same."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of reviews with 1 STAR of the SELECTED dataset:  20.0 %\n",
            "Number of reviews with 2 STARS of the SELECTED dataset:  20.0 %\n",
            "Number of reviews with 3 STARS of the SELECTED dataset:  20.0 %\n",
            "Number of reviews with 4 STARS of the SELECTED dataset:  20.0 %\n",
            "Number of reviews with 5 STARS of the SELECTED dataset:  20.0 %\n"
          ]
        }
      ],
      "source": [
        "print(f\"Number of reviews with 1 STAR of the SELECTED dataset:  {100*stars.count(0)/len(stars)} %\")\n",
        "print(f\"Number of reviews with 2 STARS of the SELECTED dataset:  {100*stars.count(1)/len(stars)} %\")\n",
        "print(f\"Number of reviews with 3 STARS of the SELECTED dataset:  {100*stars.count(2)/len(stars)} %\")\n",
        "print(f\"Number of reviews with 4 STARS of the SELECTED dataset:  {100*stars.count(3)/len(stars)} %\")\n",
        "print(f\"Number of reviews with 5 STARS of the SELECTED dataset:  {100*stars.count(4)/len(stars)} %\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Data tokenization:\n",
        "\n",
        "We now **tokenize** the reviews in order to make them readable by our neuronal network. For this we carry out the following steps:\n",
        "\n",
        "- First, we **remove punctuation** and transform **upper cases into lower cases**.\n",
        "\n",
        "- Second, we **tokenize** the words, by assigning to each of them an **integer**.\n",
        "\n",
        "- Finally, we **translate** the reviews into tokenized reviews (by replacing each word by its corresponding integer)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let us begin with punctuation and upper cases."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "food is good  service at the bar is excellent   franco dropping f bombs at the the bar is a total turn off  tell him to stay in the kitchennnwe came back 6 months later  and had the most bizarre experience  the owner chef came out of the kitchen and verbally attacked a table of patronsnhe said that he was not happy with their disappointment with one of their dinners  he challenged them to the parking lot where he was going to punch the fbomb out of them the customers told him to stand back and even asked if the police could be called  the food is still good yet over pricedngo only at your own risk\n"
          ]
        }
      ],
      "source": [
        "from string import punctuation\n",
        "\n",
        "# Remove punctuation and upper cases\n",
        "all_reviews = ' new_review_xyz '.join([review.translate(str.maketrans('', '', punctuation)) for review in reviews]) \n",
        "all_reviews = all_reviews.lower()\n",
        "\n",
        "# Split again the different reviews\n",
        "reviews_split = all_reviews.split(' new_review_xyz ')\n",
        "all_reviews = ' '.join(reviews_split)\n",
        "\n",
        "# Create a list containing all the words\n",
        "all_words = all_reviews.split()\n",
        "\n",
        "# We delete useless variables to increase available RAM\n",
        "del all_reviews\n",
        "\n",
        "# Check if all is OK with one review\n",
        "print(reviews_split[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, let us **encode the words into integers**: we do this by building a **dictionary** that maps all the present words into integers. It will permit us to **convert the reviews into a list of integers**. We **keep the value 0 for the padding**, that will be carried out next to have reviews of same size."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Count occurences of each word\n",
        "words_occurences = Counter(all_words) \n",
        "# Sort the words from the most to the least present\n",
        "words_sorted = sorted(words_occurences, key=words_occurences.get, reverse=True) \n",
        "# Build the dictionary that maps words to integers: we keep \"0\" for the padding\n",
        "word_to_integer = {word: integer for integer, word in enumerate(words_sorted, start=1)} \n",
        "\n",
        "\n",
        "## Tokenize each review in reviews_split and store the tokenized reviews in reviews_tokenized\n",
        "reviews_tokenized = []\n",
        "for review in reviews_split:\n",
        "    reviews_tokenized.append([word_to_integer[word] for word in review.split()])\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of unique words:  279087\n",
            "\n",
            "Example of tokenized review: \n",
            " [4, 6, 10, 482, 133, 5, 3545, 58405, 3330, 296, 2, 4644, 206, 6, 44, 7, 1, 206, 3875, 75, 1, 296, 4, 76, 3, 120, 25, 32535, 10600, 3331, 312, 63, 23, 3, 52, 618, 14, 120, 9070, 134, 35816, 33, 19, 74, 144, 20, 1412, 6, 669, 16, 856, 1486, 1782, 6, 10, 537, 7, 625, 375, 7, 4548, 4420, 374, 44, 429, 3742, 16, 146, 1082, 24, 605, 32, 9, 1279, 388, 1840, 553, 255, 2, 62, 85374, 100, 59, 56, 32]\n",
            "\n",
            "The same review before tokenization: \n",
            " i was in las vegas to attend asd trade show and ti hotel was one of the hotel referred by the show  i got a room at 33rd flood facing strip  which had a great view but room smelt bad furnitures as you can see on picture was dirty with dark spots nobody was in charge of taking care of hallways leftover dishes  one ice bucket with few glasses were stayed there for 24 hours  towels looks old and some dirtynnever never go back there\n"
          ]
        }
      ],
      "source": [
        "# Number of unique words\n",
        "print('Number of unique words: ', len((word_to_integer))) \n",
        "print()\n",
        "\n",
        "print('Example of tokenized review: \\n', reviews_tokenized[1])\n",
        "print()\n",
        "\n",
        "print('The same review before tokenization: \\n', reviews_split[1])\n",
        "\n",
        "\n",
        "# We delete useless variables to increase available RAM\n",
        "del all_words\n",
        "del reviews_split\n",
        "del words_occurences\n",
        "del words_sorted"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Preparation of the features matrix (containing tokenized customized reviews)\n",
        "\n",
        "We prepare the review matrix, by **standardizing** the lenght of the reviews to **300** words, to make the neuronal network comutations reasonable:\n",
        "\n",
        "- We **remove** the reviews with no text.   XXXX\n",
        "\n",
        "- We  **add zeros** to the reviews that are **too short**.   XXXX\n",
        "\n",
        "- We **truncate** reviews that are **too long**.   XXXX\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let us first **check** whether there are **reviews with no text**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of reviews with no words: 0\n"
          ]
        }
      ],
      "source": [
        "# Size of the reviews\n",
        "reviews_lenghts = [len(x) for x in reviews_tokenized]\n",
        "\n",
        "print(\"Number of reviews with no words: {}\".format(min(reviews_lenghts)))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "There are **no reviews with no words**.\n",
        "\n",
        "Now, let us check the **maximal, median, and average number of words in a review**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Maximal number of words in a review: 1025\n",
            "Median number of words in a review: 99.0\n",
            "Average number of words in a review: 133.38750714285715\n",
            "Average number of words in a review + 2 standard deviations: 374.6552661842528\n"
          ]
        }
      ],
      "source": [
        "print(\"Maximal number of words in a review: {}\".format(max(reviews_lenghts)))\n",
        "print(\"Median number of words in a review: {}\".format(np.median(reviews_lenghts)))\n",
        "print(\"Average number of words in a review: {}\".format(np.mean(reviews_lenghts)))\n",
        "print(\"Average number of words in a review + 2 standard deviations: {}\".format(np.mean(reviews_lenghts) + 2*np.std(reviews_lenghts)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Based on these statistics, we decide to customize the length of our reviews at **300 words**.\n",
        "\n",
        "Thus, let us **trunctate** reviews that are too long, and **add zeros** to reviews that are too short, to create the **matrix of features** that will be used as **predictor** in our neuronal network."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[  0   0   0   0   0]\n",
            " [  0   0   0   0   0]\n",
            " [  1 227  55  79  72]\n",
            " [  0   0   0   0   0]\n",
            " [  0   0   0   0   0]]\n"
          ]
        }
      ],
      "source": [
        "# Create the matrix of features, that will be entered in the neuronal network\n",
        "# Its size must be of (number_of_reviews * maximum_number_of_words_per_review)\n",
        "max_words_per_review = 300\n",
        "matrix_features = np.zeros((len(reviews_tokenized), max_words_per_review), dtype=int)\n",
        "\n",
        "# We put the tokenized words in the matrix, for each review (and truncate at the maximum review length)\n",
        "for review_number, words_in_review in enumerate(reviews_tokenized):\n",
        "    matrix_features[review_number, :len(words_in_review)] = np.array(words_in_review)[:max_words_per_review]\n",
        "    \n",
        "# We look at the last columns of the matrix of features (tokenized and standardized reviews), to check if all is OK\n",
        "print(matrix_features[:5, -5:])\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Transforming stars into \"good\", \"neutral\", and \"bad\" reviews\n",
        "\n",
        "We decide to group **4 and 5 stars** reviews as **\"good\"**, **3 stars** as **\"neutral\"**, and **1 and 2 stars** as **\"bad\"**.\n",
        "\n",
        "In the following, we will try to **predict** if a review is good, neutral or bad."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 5 or 4 stars => \"good\"\n",
        "good = [1 if (star == 4 or star ==3) else 0 for star in stars]\n",
        "# 3 stars => \"neutral\"\n",
        "neutral = [1 if (star == 2) else 0 for star in stars]\n",
        "# 2 or 1 star => \"bad\"\n",
        "bad = [1 if (star == 1 or star ==0) else 0 for star in stars]\n",
        "\n",
        "# 3 variables put together in a matrix\n",
        "goodness = np.array([good, neutral, bad], dtype=int)\n",
        "goodness = goodness.T"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Preparation of the training, test, and validation sets\n",
        "\n",
        "We now divide our prepared data into the **training set** (**80% of the data**), the **test set** (**10% of the data**), and the **validation set** (**10% of the data**)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\t\t\tFeature Shapes:\n",
            "Train set: \t\t(112000, 300) \n",
            "Validation set: \t(14000, 300) \n",
            "Test set: \t\t(14000, 300)\n"
          ]
        }
      ],
      "source": [
        "train_prop = 0.8\n",
        "valid_prop = 0.1\n",
        "test_prop = 1 - (train_prop+valid_prop)\n",
        "\n",
        "train_len = int(len(reviews_tokenized)*train_prop)\n",
        "valid_len = int(len(reviews_tokenized)*valid_prop)\n",
        "\n",
        "train_reviews, valid_reviews, test_reviews = matrix_features[:train_len], matrix_features[train_len:train_len+valid_len], matrix_features[train_len+valid_len:]\n",
        "train_goodness, valid_goodness, test_goodness = goodness[:train_len], goodness[train_len:train_len+valid_len], goodness[train_len+valid_len:]\n",
        "\n",
        "## We check the number of reviews in each dataset\n",
        "print(\"\\t\\t\\tFeature Shapes:\")\n",
        "print(\"Train set: \\t\\t{}\".format(train_reviews.shape), \n",
        "      \"\\nValidation set: \\t{}\".format(valid_reviews.shape),\n",
        "      \"\\nTest set: \\t\\t{}\".format(test_reviews.shape))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Building the Neuronal Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Image_classification_implemented.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "037df8b1be8044cc89d2218b3a9337e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e68cc9fc9caa4600a825ef9f35761ce6",
            "max": 170498071,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d230955a281941aea0ade95951534f7c",
            "value": 170498071
          }
        },
        "112ff4558a3c432bbab3b9a544449d80": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e9dac5c1e74b47558ac632dd9e914012",
            "placeholder": "​",
            "style": "IPY_MODEL_dae2edde1ddd468ea8e5ab926a8a475a",
            "value": " 170499072/? [00:02&lt;00:00, 90372366.01it/s]"
          }
        },
        "7c0313d2d70747369e4cdf0ebdafda89": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "82922ef6aca24f83bd5ed4377d99d6ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_de49f050694444398b181b4dd78dd06e",
              "IPY_MODEL_037df8b1be8044cc89d2218b3a9337e2",
              "IPY_MODEL_112ff4558a3c432bbab3b9a544449d80"
            ],
            "layout": "IPY_MODEL_7c0313d2d70747369e4cdf0ebdafda89"
          }
        },
        "d230955a281941aea0ade95951534f7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d269c0e0add54fe2b1319a325ec37ec3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dae2edde1ddd468ea8e5ab926a8a475a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "de49f050694444398b181b4dd78dd06e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d269c0e0add54fe2b1319a325ec37ec3",
            "placeholder": "​",
            "style": "IPY_MODEL_e36cc0c0139a49d6be89572516a83510",
            "value": ""
          }
        },
        "e36cc0c0139a49d6be89572516a83510": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e68cc9fc9caa4600a825ef9f35761ce6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e9dac5c1e74b47558ac632dd9e914012": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
